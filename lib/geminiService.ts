// lib/geminiService.ts
import { GoogleGenerativeAI } from "@google/generative-ai";

const apiKey = "AIzaSyCSQ9cQYppwfZhp4EW7U5ArgG_lKvfqaDo";
const genAI = new GoogleGenerativeAI(apiKey);

let model: any | null = null;

// ‚úÖ T·∫°o model duy nh·∫•t
export function getGeminiModel() {
  if (!model) {
    model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
    console.log("‚ö° Gemini model ready");
  }
  return model;
}

// ‚úÖ H√†m warmup
export async function warmupGemini() {
  const model = getGeminiModel();
  try {
    await model.generateContent("ping");
    console.log("‚úÖ Gemini warmed up");
  } catch (err) {
    console.warn("‚ö†Ô∏è Warmup Gemini failed:", err);
  }
}
// üßπ H√†m t√°ch JSON trong response
function extractJSON(text: string): string {
  // B·ªè codeblock
  let clean = text.replace(/```json/g, "").replace(/```/g, "").trim();

  // Regex t√¨m JSON object ƒë·∫ßu ti√™n
  const match = clean.match(/\{[\s\S]*\}/);
  if (match) {
    return match[0];
  }
  throw new Error("Kh√¥ng t√¨m th·∫•y JSON trong response: " + text);
}

// üîÑ H√†m g·ªçi Gemini c√≥ retry
async function callWithRetry(model: any, prompt: string, retries = 3, delay = 30000) {
  for (let attempt = 0; attempt < retries; attempt++) {
    try {
      const result = await model.generateContent(prompt);
      const raw = result.response.text();
      const jsonStr = extractJSON(raw);
      return JSON.parse(jsonStr);
    } catch (err: any) {
      if (err.message?.includes("429") && attempt < retries - 1) {
        console.warn(`‚ö†Ô∏è Quota exceeded. Th·ª≠ l·∫°i sau ${delay / 1000}s...`);
        await new Promise((res) => setTimeout(res, delay));
      } else if (err instanceof SyntaxError) {
        console.error("‚ùå JSON parse error:", err);
        throw new Error("Gemini tr·∫£ v·ªÅ d·ªØ li·ªáu kh√¥ng h·ª£p l·ªá");
      } else {
        throw err;
      }
    }
  }
  throw new Error("Gemini API failed sau nhi·ªÅu l·∫ßn retry");
}
// =====================
// üìå C√°c h√†m export
// =====================

// 1. T√≥m t·∫Øt b√†i h·ªçc
export async function generateSummary(inputContent: string, lessonContent: string) {
  const model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });

  const prompt = `B·∫°n l√† m·ªôt tr·ª£ l√Ω AI gi√∫p t√≥m t·∫Øt n·ªôi dung h·ªçc t·∫≠p.

N·∫øu ng∆∞·ªùi d√πng nh·∫≠p th√™m n·ªôi dung (inputContent), h√£y ∆∞u ti√™n d√πng n√≥ ƒë·ªÉ t·∫°o t√≥m t·∫Øt.
N·∫øu inputContent r·ªóng, h√£y d√πng lessonContent.

N·ªôi dung ng∆∞·ªùi d√πng nh·∫≠p th√™m:
${inputContent}

N·ªôi dung b√†i h·ªçc:
${lessonContent}

Y√™u c·∫ßu: 
- T√≥m t·∫Øt th√†nh 1 ti√™u ƒë·ªÅ ng·∫Øn g·ªçn v√† 1 ƒëo·∫°n t√≥m t·∫Øt s√∫c t√≠ch.
- Tr·∫£ v·ªÅ JSON ƒë√∫ng chu·∫©n, kh√¥ng k√®m vƒÉn b·∫£n th·ª´a.

C·∫•u tr√∫c JSON:
{
  "title": "ti√™u ƒë·ªÅ ng·∫Øn g·ªçn",
  "summary": "ƒëo·∫°n t√≥m t·∫Øt s√∫c t√≠ch"
}`;

  return await callWithRetry(model, prompt);
}

// 2. Sinh c√¢u h·ªèi luy·ªán t·∫≠p
export async function generateQuestions(prompt: string) {
  const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });
  return await callWithRetry(model, prompt);
}

// 3. Ph√¢n t√≠ch n√¢ng l·ª±c h·ªçc t·∫≠p (c√≥ th√™m d·ªØ li·ªáu chart)
export async function generateAnalysis(lessons: any[], practices: any[], feedbacks: any[]) {
  const model = genAI.getGenerativeModel({ model: "gemini-2.5-flash" });

  // üîπ R√∫t g·ªçn d·ªØ li·ªáu tr∆∞·ªõc khi g·ª≠i ƒë·ªÉ tr√°nh quota
  const lessonData = lessons.map((l) => ({ id: l.id, title: l.title }));
  const practiceData = practices.map((p) => ({
    lessonId: p.lessonId,
    score: p.score,
    total: p.details?.length || 0,
  }));
  const feedbackData = feedbacks.map((f) => ({ rating: f.rating, comment: f.comment }));

  const prompt = `
H√£y ph√¢n t√≠ch nƒÉng l·ª±c h·ªçc t·∫≠p d·ª±a tr√™n d·ªØ li·ªáu:

1. Danh s√°ch b√†i h·ªçc: ${JSON.stringify(lessonData)}
2. K·∫øt qu·∫£ luy·ªán t·∫≠p: ${JSON.stringify(practiceData)}
3. C√°c feedback c·ªßa h·ªçc vi√™n: ${JSON.stringify(feedbackData)}

Y√™u c·∫ßu:
- ƒê√°nh gi√° chi ti·∫øt nƒÉng l·ª±c hi·ªán t·∫°i (ƒëi·ªÉm m·∫°nh, ƒëi·ªÉm y·∫øu).
- Ph√¢n t√≠ch d·ª±a tr√™n k·∫øt qu·∫£ luy·ªán t·∫≠p v√† ph·∫£n h·ªìi.
- ƒê∆∞a ra g·ª£i √Ω h∆∞·ªõng h·ªçc t·∫≠p c·ª• th·ªÉ ƒë·ªÉ c·∫£i thi·ªán.
- T·∫°o d·ªØ li·ªáu bi·ªÉu ƒë·ªì (chart data) c√≥ th·ªÉ tr·ª±c quan h√≥a ƒë∆∞·ª£c.

Tr·∫£ v·ªÅ JSON v·ªõi c·∫•u tr√∫c sau:
{
  "overview": "T·ªïng quan nƒÉng l·ª±c...",
  "practiceAnalysis": "Ph√¢n t√≠ch d·ª±a tr√™n luy·ªán t·∫≠p...",
  "feedbackAnalysis": "Ph√¢n t√≠ch d·ª±a tr√™n ph·∫£n h·ªìi...",
  "suggestions": ["G·ª£i √Ω 1", "G·ª£i √Ω 2", "G·ª£i √Ω 3"],
  "charts": {
    "practiceChart": {
      "title": "ƒêi·ªÉm trung b√¨nh theo b√†i h·ªçc",
      "type": "bar",
      "data": [
        { "lessonTitle": "B√†i 1", "averageScore": 8.5 },
        { "lessonTitle": "B√†i 2", "averageScore": 7.0 }
      ]
    },
    "feedbackChart": {
      "title": "Ph√¢n b·ªë ƒë√°nh gi√° c·ªßa h·ªçc vi√™n",
      "type": "pie",
      "data": [
        { "rating": 5, "count": 10 },
        { "rating": 4, "count": 4 },
        { "rating": 3, "count": 2 }
      ]
    },
    "progressChart": {
      "title": "Xu h∆∞·ªõng ƒëi·ªÉm luy·ªán t·∫≠p theo th·ªùi gian",
      "type": "line",
      "data": [
        { "date": "2025-09-01", "averageScore": 7.2 },
        { "date": "2025-09-10", "averageScore": 8.0 },
        { "date": "2025-09-20", "averageScore": 8.8 }
      ]
    }
  }
}
- Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng gi·∫£i th√≠ch th√™m.
`;

  return await callWithRetry(model, prompt);
}
export async function askGemini(prompt: string, context: any = {}) {
  const model = getGeminiModel();

  // üîπ T√°ch d·ªØ li·ªáu lessons ra kh·ªèi context
  const lessons = context.lessons || [];
  const topics = context.topics || [];
  const otherContext = { ...context };
  delete otherContext.lessons;
  delete otherContext.topics;

  // üß© Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc chunk (10 b√†i / chunk)
  const CHUNK_SIZE = 1;
  const chunks: any[][] = [];
  for (let i = 0; i < lessons.length; i += CHUNK_SIZE) {
    chunks.push(lessons.slice(i, i + CHUNK_SIZE));
  }

  // üß† N·∫øu kh√¥ng c√≥ b√†i h·ªçc, ch·ªâ g·ª≠i context th√¥ng th∆∞·ªùng
  if (chunks.length === 0) {
    const contextText = JSON.stringify(otherContext, null, 2);
    const fullPrompt = `
B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa trang web h·ªçc t·∫≠p.
D·ªØ li·ªáu trang web:
${contextText}

Ng∆∞·ªùi d√πng h·ªèi: "${prompt}"

H√£y tr·∫£ l·ªùi t·ª± nhi√™n, r√µ r√†ng, c√≥ th·ªÉ ch√®n link ch√≠nh x√°c n·∫øu ph√π h·ª£p.
N·∫øu kh√¥ng ch·∫Øc ch·∫Øn, h√£y n√≥i l·ªãch s·ª±.
`;
    const result = await model.generateContent(fullPrompt);
    return result.response.text();
  }

  // üöÄ N·∫øu c√≥ nhi·ªÅu b√†i h·ªçc, g·ª≠i t·ª´ng chunk
  let combinedResponse = "";
  for (let i = 0; i < chunks.length; i++) {
    const miniContext = {
      ...otherContext,
      lessons: chunks[i].map((l) => ({
        id: l.id,
        title: l.title,
        topic: l.topic,
      })),
      topics,
    };

    const contextText = JSON.stringify(miniContext, null, 2);
    const chunkPrompt = `
B·∫°n l√† tr·ª£ l√Ω ·∫£o c·ªßa trang web h·ªçc t·∫≠p.
ƒê√¢y l√† ph·∫ßn d·ªØ li·ªáu ${i + 1}/${chunks.length}:
${contextText}

Ng∆∞·ªùi d√πng h·ªèi: "${prompt}"

H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, r√µ r√†ng, v√† ch·ªâ d·ª±a tr√™n d·ªØ li·ªáu trong ph·∫ßn n√†y.
N·∫øu c·∫ßn t·ªïng h·ª£p, h√£y g·ªôp th√¥ng tin c√°c ph·∫ßn tr∆∞·ªõc ƒë√≥.
`;

    try {
      const result = await model.generateContent(chunkPrompt);
      combinedResponse += result.response.text() + "\n";
    } catch (error: any) {
      if (error.message?.includes("429")) {
        console.warn(`‚ö†Ô∏è Quota exceeded ·ªü chunk ${i + 1}, ch·ªù 35s...`);
        await new Promise((res) => setTimeout(res, 35000));
        i--; // th·ª≠ l·∫°i chunk n√†y
      } else {
        console.error(error);
      }
    }
  }

  // ‚ú® G·ª≠i y√™u c·∫ßu t·ªïng h·ª£p cu·ªëi c√πng
  const summaryPrompt = `
D∆∞·ªõi ƒë√¢y l√† c√°c c√¢u tr·∫£ l·ªùi t·∫°m th·ªùi t·ª´ t·ª´ng ph·∫ßn d·ªØ li·ªáu:
${combinedResponse}

H√£y t·ªïng h·ª£p ch√∫ng l·∫°i th√†nh m·ªôt c√¢u tr·∫£ l·ªùi ho√†n ch·ªânh, r√µ r√†ng v√† t·ª± nhi√™n cho c√¢u h·ªèi:
"${prompt}"
`;
  const summaryResult = await model.generateContent(summaryPrompt);
  return summaryResult.response.text().trim();
}